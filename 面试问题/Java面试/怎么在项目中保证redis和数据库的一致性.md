### 1. 先删缓存，再更新数据库

- **流程：** `Delete Cache` -> `Update DB`
    
- **问题：** 存在严重的**并发漏洞**。如果线程 A 删了缓存还没更新完 DB，线程 B 进来发现缓存为空，去读了 DB 的旧数据并回写到缓存，导致缓存里永远是脏数据。
    
- **解决方案：** **延时双删**。在更新完 DB 后，先休眠一小会儿（如 500ms），再次删除缓存。
    

### 2. 先更新数据库，再删缓存（主流推荐）

- **流程：** `Update DB` -> `Delete Cache`
    
- **原理：** 这是 **Cache Aside Pattern** 的核心建议。
    
- **优点：** 出现脏数据的概率极低（除非缓存刚好失效，且读写并发极高）。
    
- **痛点：** 如果第二步“删除缓存”失败了，缓存里就是旧值，DB 里是新值，发生了不一致。
    

### 3. 如何解决“删除缓存失败”？

针对方案 2 的失败情况，有以下两种进阶手段：

#### A. 消息队列补偿机制

1. 执行更新数据库操作。
    
2. 删除缓存失败，将失败的 Key 发送到**消息队列（MQ）**。
    
3. 消费端不断重试，直到删除成功。
    

#### B. 监听 Binlog 异步删除（最优雅）

1. 通过 **Canal**（阿里开源工具）伪装成 MySQL 的从库，实时监听数据库的 **Binlog** 日志。
    
2. 当发现目标表有更新操作时，Canal 异步通知程序去删除对应的 Redis 缓存。
    

- **优点：** 对业务代码零侵入，解耦彻底。

### 4. 方案对比表

|**方案**|**优点**|**缺点**|**适用场景**|
|---|---|---|---|
|**延时双删**|简单，能解决大部分脏读|延时时间难把控，吞吐量受损|中低并发，业务逻辑简单|
|**MQ 重试**|保证最终一致性，成功率高|引入 MQ，系统变复杂|对一致性有要求，允许短时间不一致|
|**Canal 监听**|业务无侵入，性能高，解耦|运维成本高|中大型分布式系统|

### 5. 补充：强一致性方案 (分布式锁)

如果业务要求**必须**实时一致（比如金融账户），可以给读写操作加**分布式锁**（如 Redisson 的读写锁 `RReadWriteLock`）。

- **写请求：** 获取写锁，阻塞读。
    
- **读请求：** 获取读锁，支持并发读，但会被写锁阻塞。
    
- **后果：** 这种方案会让 Redis 性能退化，慎用。